{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras_example_MLP_minimo.ipynb","version":"0.3.2","provenance":[{"file_id":"1Msh4cLcjnhzoqDvJyqVELcqHZKZYl2fk","timestamp":1551434518723}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GK2PglL1iP4Q","colab_type":"code","outputId":"0958c23a-2dd0-41cb-b9cd-348733730785","executionInfo":{"status":"ok","timestamp":1562329937837,"user_tz":-120,"elapsed":1743,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.optimizers import SGD\n","\n","# DATOS ALEATORIOS\n","import numpy as np\n","x_train = np.random.random((1000, 20))\n","y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xyLv99eTtotI","colab_type":"code","outputId":"207fd8b7-761e-4e36-d481-999f467df5c3","executionInfo":{"status":"ok","timestamp":1562330014687,"user_tz":-120,"elapsed":12955,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# MODELO MÍNIMO KERAS\n","# DEFINICION DEL MODELO\n","model = Sequential()\n","model.add(Dense(100, activation='softmax', input_dim=(20)))\n","model.add(Dense(10, activation='softmax'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","\n","# DEFINICION DE FUNCIÓN DE COSTE, Y OPTIMIZADOR\n","model.compile(loss='mean_squared_error',optimizer='SGD')\n","\n","# ENTRENAMIENTO\n","model.fit(x_train, y_train,epochs = 100)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0705 12:33:21.891409 140649649186688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0705 12:33:21.932341 140649649186688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0705 12:33:21.938921 140649649186688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0705 12:33:21.987491 140649649186688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0705 12:33:22.135194 140649649186688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","W0705 12:33:22.168085 140649649186688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","1000/1000 [==============================] - 4s 4ms/step - loss: 0.0902\n","Epoch 2/100\n","1000/1000 [==============================] - 0s 86us/step - loss: 0.0902\n","Epoch 3/100\n","1000/1000 [==============================] - 0s 90us/step - loss: 0.0902\n","Epoch 4/100\n","1000/1000 [==============================] - 0s 88us/step - loss: 0.0902\n","Epoch 5/100\n","1000/1000 [==============================] - 0s 107us/step - loss: 0.0902\n","Epoch 6/100\n","1000/1000 [==============================] - 0s 92us/step - loss: 0.0902\n","Epoch 7/100\n","1000/1000 [==============================] - 0s 94us/step - loss: 0.0902\n","Epoch 8/100\n","1000/1000 [==============================] - 0s 85us/step - loss: 0.0902\n","Epoch 9/100\n","1000/1000 [==============================] - 0s 87us/step - loss: 0.0902\n","Epoch 10/100\n","1000/1000 [==============================] - 0s 84us/step - loss: 0.0902\n","Epoch 11/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0902\n","Epoch 12/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 13/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 14/100\n","1000/1000 [==============================] - 0s 93us/step - loss: 0.0902\n","Epoch 15/100\n","1000/1000 [==============================] - 0s 84us/step - loss: 0.0902\n","Epoch 16/100\n","1000/1000 [==============================] - 0s 98us/step - loss: 0.0902\n","Epoch 17/100\n","1000/1000 [==============================] - 0s 82us/step - loss: 0.0902\n","Epoch 18/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0902\n","Epoch 19/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 20/100\n","1000/1000 [==============================] - 0s 83us/step - loss: 0.0902\n","Epoch 21/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 22/100\n","1000/1000 [==============================] - 0s 78us/step - loss: 0.0902\n","Epoch 23/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0902\n","Epoch 24/100\n","1000/1000 [==============================] - 0s 105us/step - loss: 0.0902\n","Epoch 25/100\n","1000/1000 [==============================] - 0s 83us/step - loss: 0.0902\n","Epoch 26/100\n","1000/1000 [==============================] - 0s 82us/step - loss: 0.0902\n","Epoch 27/100\n","1000/1000 [==============================] - 0s 83us/step - loss: 0.0902\n","Epoch 28/100\n","1000/1000 [==============================] - 0s 85us/step - loss: 0.0902\n","Epoch 29/100\n","1000/1000 [==============================] - 0s 82us/step - loss: 0.0902\n","Epoch 30/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0902\n","Epoch 31/100\n","1000/1000 [==============================] - 0s 74us/step - loss: 0.0902\n","Epoch 32/100\n","1000/1000 [==============================] - 0s 86us/step - loss: 0.0902\n","Epoch 33/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0902\n","Epoch 34/100\n","1000/1000 [==============================] - 0s 78us/step - loss: 0.0902\n","Epoch 35/100\n","1000/1000 [==============================] - 0s 84us/step - loss: 0.0902\n","Epoch 36/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 37/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 38/100\n","1000/1000 [==============================] - 0s 76us/step - loss: 0.0902\n","Epoch 39/100\n","1000/1000 [==============================] - 0s 74us/step - loss: 0.0902\n","Epoch 40/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0902\n","Epoch 41/100\n","1000/1000 [==============================] - 0s 87us/step - loss: 0.0902\n","Epoch 42/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0902\n","Epoch 43/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 44/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 45/100\n","1000/1000 [==============================] - 0s 83us/step - loss: 0.0902\n","Epoch 46/100\n","1000/1000 [==============================] - 0s 85us/step - loss: 0.0902\n","Epoch 47/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0902\n","Epoch 48/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0902\n","Epoch 49/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0902\n","Epoch 50/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0902\n","Epoch 51/100\n","1000/1000 [==============================] - 0s 90us/step - loss: 0.0902\n","Epoch 52/100\n","1000/1000 [==============================] - 0s 85us/step - loss: 0.0902\n","Epoch 53/100\n","1000/1000 [==============================] - 0s 95us/step - loss: 0.0902\n","Epoch 54/100\n","1000/1000 [==============================] - 0s 84us/step - loss: 0.0902\n","Epoch 55/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0902\n","Epoch 56/100\n","1000/1000 [==============================] - 0s 87us/step - loss: 0.0902\n","Epoch 57/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0902\n","Epoch 58/100\n","1000/1000 [==============================] - 0s 82us/step - loss: 0.0902\n","Epoch 59/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0901\n","Epoch 60/100\n","1000/1000 [==============================] - 0s 86us/step - loss: 0.0901\n","Epoch 61/100\n","1000/1000 [==============================] - 0s 78us/step - loss: 0.0901\n","Epoch 62/100\n","1000/1000 [==============================] - 0s 75us/step - loss: 0.0901\n","Epoch 63/100\n","1000/1000 [==============================] - 0s 85us/step - loss: 0.0901\n","Epoch 64/100\n","1000/1000 [==============================] - 0s 82us/step - loss: 0.0901\n","Epoch 65/100\n","1000/1000 [==============================] - 0s 102us/step - loss: 0.0901\n","Epoch 66/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0901\n","Epoch 67/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0901\n","Epoch 68/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0901\n","Epoch 69/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0901\n","Epoch 70/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0901\n","Epoch 71/100\n","1000/1000 [==============================] - 0s 78us/step - loss: 0.0901\n","Epoch 72/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0901\n","Epoch 73/100\n","1000/1000 [==============================] - 0s 83us/step - loss: 0.0901\n","Epoch 74/100\n","1000/1000 [==============================] - 0s 82us/step - loss: 0.0901\n","Epoch 75/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0901\n","Epoch 76/100\n","1000/1000 [==============================] - 0s 84us/step - loss: 0.0901\n","Epoch 77/100\n","1000/1000 [==============================] - 0s 76us/step - loss: 0.0901\n","Epoch 78/100\n","1000/1000 [==============================] - 0s 90us/step - loss: 0.0901\n","Epoch 79/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0901\n","Epoch 80/100\n","1000/1000 [==============================] - 0s 75us/step - loss: 0.0901\n","Epoch 81/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0901\n","Epoch 82/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0901\n","Epoch 83/100\n","1000/1000 [==============================] - 0s 86us/step - loss: 0.0901\n","Epoch 84/100\n","1000/1000 [==============================] - 0s 82us/step - loss: 0.0901\n","Epoch 85/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0901\n","Epoch 86/100\n","1000/1000 [==============================] - 0s 84us/step - loss: 0.0901\n","Epoch 87/100\n","1000/1000 [==============================] - 0s 77us/step - loss: 0.0901\n","Epoch 88/100\n","1000/1000 [==============================] - 0s 78us/step - loss: 0.0901\n","Epoch 89/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0901\n","Epoch 90/100\n","1000/1000 [==============================] - 0s 86us/step - loss: 0.0901\n","Epoch 91/100\n","1000/1000 [==============================] - 0s 78us/step - loss: 0.0901\n","Epoch 92/100\n","1000/1000 [==============================] - 0s 80us/step - loss: 0.0901\n","Epoch 93/100\n","1000/1000 [==============================] - 0s 83us/step - loss: 0.0901\n","Epoch 94/100\n","1000/1000 [==============================] - 0s 84us/step - loss: 0.0901\n","Epoch 95/100\n","1000/1000 [==============================] - 0s 86us/step - loss: 0.0901\n","Epoch 96/100\n","1000/1000 [==============================] - 0s 81us/step - loss: 0.0901\n","Epoch 97/100\n","1000/1000 [==============================] - 0s 75us/step - loss: 0.0901\n","Epoch 98/100\n","1000/1000 [==============================] - 0s 79us/step - loss: 0.0901\n","Epoch 99/100\n","1000/1000 [==============================] - 0s 83us/step - loss: 0.0901\n","Epoch 100/100\n","1000/1000 [==============================] - 0s 76us/step - loss: 0.0901\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7feb4301bac8>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"BDtznPCdtmVm","colab_type":"code","outputId":"bb2402ef-277b-4250-d379-08841007c308","executionInfo":{"status":"ok","timestamp":1558114779303,"user_tz":-120,"elapsed":772,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# EVALUACIÓN\n","score = model.evaluate(x_train, y_train, batch_size=128)\n","\n","# PREDICCIÓN\n","y_hat = model.predict(x_train)\n","\n","print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1000/1000 [==============================] - 0s 50us/step\n","0.09006969422101975\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I-RzBtBJHQ1S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}