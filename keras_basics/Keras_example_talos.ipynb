{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras_example_talos.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Obl3eXMvWvtR","colab_type":"code","colab":{}},"source":["from numpy import loadtxt\n","\n","dataset = loadtxt(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", delimiter=\",\")\n","x = dataset[:,0:8]\n","y = dataset[:,8]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iz_VsZZIZ3gN","colab_type":"code","outputId":"9e468dac-ec94-4268-8b19-18b54e24a00b","executionInfo":{"status":"ok","timestamp":1559993104960,"user_tz":-120,"elapsed":882,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x.shape"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 8)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"NsxMIgo-Z5Bv","colab_type":"code","outputId":"01f4ef22-5563-42b7-cc45-54f9304d9009","executionInfo":{"status":"ok","timestamp":1559993104965,"user_tz":-120,"elapsed":846,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["y.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768,)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"bfk8CWuSonVC","colab_type":"text"},"source":["# Otros datasets\n","https://github.com/jbrownlee/Datasets"]},{"cell_type":"code","metadata":{"id":"W0abbrJwYc3v","colab_type":"code","outputId":"7b35cf88-9fc8-42c9-99c3-aae6688e797c","executionInfo":{"status":"ok","timestamp":1559993108523,"user_tz":-120,"elapsed":2406,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.models import Sequential\n","from keras.layers import Dense"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OSee4G0tu8JP","colab_type":"text"},"source":["# Así lo haríamos de normal"]},{"cell_type":"code","metadata":{"id":"03heDZoLYe7p","colab_type":"code","colab":{}},"source":["def diabetes(X,Y):\n","    \n","    model = Sequential()\n","    model.add(Dense(12, input_dim=8, activation='relu'))\n","    model.add(Dense(8, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.fit(X, Y, epochs=100, batch_size=10, verbose=0)\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWBv4kTfaRsb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":384},"outputId":"afc2abfd-017a-46b8-8c49-24d9ca51dbe8","executionInfo":{"status":"ok","timestamp":1559993172139,"user_tz":-120,"elapsed":31998,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}}},"source":["model = diabetes(x,y) \n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 12)                108       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 8)                 104       \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 9         \n","=================================================================\n","Total params: 221\n","Trainable params: 221\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FYlqj_7QaFgK","colab_type":"text"},"source":["# Así lo hacemos con Talos"]},{"cell_type":"code","metadata":{"id":"HBuiPLiqYivN","colab_type":"code","colab":{}},"source":["from keras.activations import relu, elu\n","\n","p = {\n","    'first_neuron': [12, 24, 48],\n","    'activation': [relu, elu],\n","    'batch_size': [10, 20, 30]\n","}\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ35r5-9Ymiv","colab_type":"code","colab":{}},"source":["# add input parameters to the function\n","def diabetes(x_train, y_train, x_val, y_val, params):\n","    \n","    # replace the hyperparameter inputs with references to params dictionary \n","    model = Sequential()\n","    model.add(Dense(params['first_neuron'], input_dim=8, activation=params['activation']))\n","    #model.add(Dense(8, activation=params['activation']))\n","    model.add(Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    # make sure history object is returned by model.fit()\n","    out = model.fit(x, y,\n","                    epochs=100,\n","                    batch_size=params['batch_size'],\n","                    #validation_split=.3,\n","                    verbose=0)\n","    \n","    # modify the output model\n","    return out, model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNu6OHOuYpJT","colab_type":"code","outputId":"ade4a7c3-a6ae-465d-d660-5b5a1595f7f8","executionInfo":{"status":"ok","timestamp":1559993238078,"user_tz":-120,"elapsed":31190,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":1226}},"source":["!pip install talos\n","import talos as ta"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting talos\n","  Downloading https://files.pythonhosted.org/packages/74/26/c44a51af579835c873e878b99c68fcba08107cdfc22d72ac4ecbc027f158/talos-0.4.9.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from talos) (1.16.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from talos) (0.24.2)\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from talos) (2.2.4)\n","Collecting astetik (from talos)\n","  Downloading https://files.pythonhosted.org/packages/03/c7/d074a03a59f55708cacb875c008bf375028c452a1ffcc452762a3c3dfed2/astetik-1.9.8.tar.gz\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from talos) (0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from talos) (4.31.0)\n","Collecting chances (from talos)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/8a/e0ce40affac9c5292da615375cd2ce979728b8f5a5d3afd4a9e3acdf9166/chances-0.1.6.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 17.8MB/s \n","\u001b[?25hCollecting kerasplotlib (from talos)\n","  Downloading https://files.pythonhosted.org/packages/e8/2e/b8628bfef6a817da9be863f650cf67187676b10d27d94b23f248da35d2b4/kerasplotlib-0.1.4.tar.gz\n","Collecting wrangle (from talos)\n","  Downloading https://files.pythonhosted.org/packages/17/9d/43d42e8bb95ef067635494fa8a0219a97d100c7ff96fb825ac01b72670b9/wrangle-0.6.4.tar.gz\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from talos) (2.21.0)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2.5.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->talos) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.2.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->talos) (2.8.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.0.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.1.0)\n","Collecting geonamescache (from astetik->talos)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/34/5daf3ed920ffaf761615addbdbb6d91dc802a36c68551e7c6568fe20d7f6/geonamescache-1.0.2-py3-none-any.whl (781kB)\n","\u001b[K     |████████████████████████████████| 788kB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->talos) (0.20.2)\n","Collecting matplotlib==2.2.3 (from chances->talos)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/59/f235ab21bbe7b7c6570c4abf17ffb893071f4fa3b9cf557b09b60359ad9a/matplotlib-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\n","\u001b[K     |████████████████████████████████| 12.6MB 41.0MB/s \n","\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from wrangle->talos) (0.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2019.3.9)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (1.24.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->chances->talos) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->chances->talos) (2.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->chances->talos) (1.1.0)\n","Requirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from statsmodels->wrangle->talos) (0.5.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==2.2.3->chances->talos) (41.0.1)\n","Building wheels for collected packages: talos, astetik, chances, kerasplotlib, wrangle\n","  Building wheel for talos (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/eb/6b/c0/5b58a4767728bb467656ccd70b4fc2e286840c1e8ffa2631ac\n","  Building wheel for astetik (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/ba/cc/e9/11c6a853d8379f295e17b68f2139ea1bbcd13c5b260822abc7\n","  Building wheel for chances (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/61/12/37/957767d4ed95919b90081079c6eb74f83927930e652b30fa93\n","  Building wheel for kerasplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/36/6b/4c/e1fc6d7d8811940fbea1147b1519c7baa6933e4baeff904433\n","  Building wheel for wrangle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/76/15/d0/e8ec4c2485b5e4acf35517f32fcdf326e199274cf32690a4ea\n","Successfully built talos astetik chances kerasplotlib wrangle\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: wrangle, geonamescache, astetik, matplotlib, chances, kerasplotlib, talos\n","  Found existing installation: matplotlib 3.0.3\n","    Uninstalling matplotlib-3.0.3:\n","      Successfully uninstalled matplotlib-3.0.3\n","Successfully installed astetik-1.9.8 chances-0.1.6 geonamescache-1.0.2 kerasplotlib-0.1.4 matplotlib-2.2.3 talos-0.4.9 wrangle-0.6.4\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Mg3Gmi4wYzLC","colab_type":"code","colab":{}},"source":["t = ta.Scan(x, y, p, diabetes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHEL_tvWjL2f","colab_type":"text"},"source":["# ESTRATEGIAS DE OPTIMIZACIÓN\n","\n","https://autonomio.github.io/docs_talos/#optimization-strategies\n"]},{"cell_type":"markdown","metadata":{"id":"BV4gsq-QjU5a","colab_type":"text"},"source":["Por defecto hace grid search, pero también se puede hacer random. Por ejemplo:"]},{"cell_type":"code","metadata":{"id":"EqHXaUVJZ-Z9","colab_type":"code","outputId":"bd9d939e-e3bc-4bc5-85a8-0b638b0d2ee7","executionInfo":{"status":"ok","timestamp":1552671898105,"user_tz":-60,"elapsed":152165,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":216}},"source":["t2 = ta.Scan(x, y, p, diabetes,grid_downsample=.5,random_method='quantum')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n"," 11%|█         | 1/9 [00:09<01:16,  9.55s/it]\u001b[A\n"," 22%|██▏       | 2/9 [00:23<01:16, 10.86s/it]\u001b[A\n"," 33%|███▎      | 3/9 [00:32<01:02, 10.43s/it]\u001b[A\n"," 44%|████▍     | 4/9 [00:46<00:57, 11.50s/it]\u001b[A\n"," 56%|█████▌    | 5/9 [00:56<00:43, 10.88s/it]\u001b[A\n"," 67%|██████▋   | 6/9 [01:10<00:35, 11.74s/it]\u001b[A\n"," 78%|███████▊  | 7/9 [01:36<00:32, 16.20s/it]\u001b[A\n"," 89%|████████▉ | 8/9 [02:03<00:19, 19.40s/it]\u001b[A\n","100%|██████████| 9/9 [02:30<00:00, 21.58s/it]\u001b[A\n","\u001b[A"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qk83uVKgkKlf","colab_type":"text"},"source":["Hay otros parámetros: probabilistic reduction, early stopping "]},{"cell_type":"code","metadata":{"id":"YbnJQ282i9Tq","colab_type":"code","outputId":"1de25df4-a0d1-4fcc-96be-501b7e9eabd6","executionInfo":{"status":"ok","timestamp":1559993356501,"user_tz":-120,"elapsed":53575,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":165}},"source":["t2 = ta.Scan(x, y, p, diabetes,\n","             grid_downsample=.2,\n","             random_method='quantum',\n","             print_params=True,\n","             experiment_no='experiment_log',\n","             dataset_name='pru')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'first_neuron': 12, 'activation': <function relu at 0x7f58149801e0>, 'batch_size': 20}\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|███▎      | 1/3 [00:13<00:26, 13.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'first_neuron': 24, 'activation': <function elu at 0x7f5814971f28>, 'batch_size': 10}\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|██████▋   | 2/3 [00:32<00:14, 14.99s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'first_neuron': 48, 'activation': <function elu at 0x7f5814971f28>, 'batch_size': 10}\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 3/3 [00:51<00:00, 16.25s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g7J7zhRZC4bZ","colab_type":"code","outputId":"563adfc1-8161-40e6-c6b0-0d3032e36bc0","executionInfo":{"status":"ok","timestamp":1559993364573,"user_tz":-120,"elapsed":685,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["ta.Deploy(t2,'modelo',metric='acc')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Deploy package modelo have been saved.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<talos.commands.deploy.Deploy at 0x7f57d2fbb828>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"SQV2Ey2RR7n-","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","rr = ta.Restore('modelo.zip')\n","model = rr.model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBBWycbDGpHJ","colab_type":"code","outputId":"1665ed2b-f67b-4257-82b4-02983973d7e9","executionInfo":{"status":"ok","timestamp":1559993411221,"user_tz":-120,"elapsed":658,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 48)                432       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 49        \n","=================================================================\n","Total params: 481\n","Trainable params: 481\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"61LsGa4JlLWw","colab_type":"text"},"source":["REPORTING"]},{"cell_type":"code","metadata":{"id":"UYlU1gEtk841","colab_type":"code","colab":{}},"source":["r = ta.Reporting('pru_experiment_log.csv')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQ3BUKrlmX5j","colab_type":"code","outputId":"982f6316-9c9d-4f67-aaae-caf93cd86823","executionInfo":{"status":"ok","timestamp":1559993440854,"user_tz":-120,"elapsed":1342,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["# returns the results dataframe\n","r.data\n"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>round_epochs</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>first_neuron</th>\n","      <th>activation</th>\n","      <th>batch_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100</td>\n","      <td>0.542649</td>\n","      <td>0.743490</td>\n","      <td>12</td>\n","      <td>&lt;function relu at 0x7f58149801e0&gt;</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100</td>\n","      <td>0.463062</td>\n","      <td>0.786458</td>\n","      <td>24</td>\n","      <td>&lt;function elu at 0x7f5814971f28&gt;</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100</td>\n","      <td>0.467513</td>\n","      <td>0.798177</td>\n","      <td>48</td>\n","      <td>&lt;function elu at 0x7f5814971f28&gt;</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   round_epochs      loss  ...                         activation  batch_size\n","0           100  0.542649  ...  <function relu at 0x7f58149801e0>          20\n","1           100  0.463062  ...   <function elu at 0x7f5814971f28>          10\n","2           100  0.467513  ...   <function elu at 0x7f5814971f28>          10\n","\n","[3 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"aQKMJ7MPnGaA","colab_type":"code","outputId":"9ac8dd03-7b5e-4dd4-e30b-3e2c370885e9","executionInfo":{"status":"ok","timestamp":1559993456977,"user_tz":-120,"elapsed":614,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# returns the highest value for 'val_fmeasure'\n","r.high(metric='acc')"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7981770810050269"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"_rfjcIyxmIrv","colab_type":"code","outputId":"b87582db-e0ad-4dd2-e089-ce3d5a01c513","executionInfo":{"status":"ok","timestamp":1559993459015,"user_tz":-120,"elapsed":871,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":480}},"source":["%matplotlib inline\n","# draws a histogram for 'val_acc'\n","r.plot_hist(metric='acc')\n"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAsQAAAHPCAYAAABUeszdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 720x475.2 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"k1RAG55dEHtP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VgFAWmacIdkp","colab_type":"text"},"source":["# Un poco mas complicado"]},{"cell_type":"code","metadata":{"id":"YZd3YwxMIeI6","colab_type":"code","colab":{}},"source":["from talos.model.layers import hidden_layers\n","\n","# add input parameters to the function\n","def diabetes(x_train, y_train, x_val, y_val, params):\n","    \n","    # replace the hyperparameter inputs with references to params dictionary \n","    model = Sequential()\n","    model.add(Dense(params['first_neuron'], input_dim=8, activation=params['activation']))\n","    hidden_layers(model, params, 1)\n","    #model.add(Dense(8, activation=params['activation']))\n","    model.add(Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    # make sure history object is returned by model.fit()\n","    out = model.fit(x, y,\n","                    epochs=100,\n","                    batch_size=params['batch_size'],\n","                    #validation_split=.3,\n","                    verbose=0)\n","    \n","    # modify the output model\n","    return out, model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQW7_9v0Kr2w","colab_type":"code","colab":{}},"source":["p = {\n","    'first_neuron': [12, 24, 48],\n","    'hidden_layers': [0,1,2],\n","    'activation': [relu, elu],\n","    'dropout': (0, 0.5, 5),\n","    'batch_size': [10, 20, 30]\n","}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlAOA2mpK9EZ","colab_type":"code","outputId":"16625910-fcb0-4a4e-b271-f2b28fa5a76f","executionInfo":{"status":"error","timestamp":1552672881740,"user_tz":-60,"elapsed":218683,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":1765}},"source":["t3 = ta.Scan(x, y, p, diabetes,grid_downsample=.5,random_method='quantum',             \n","             experiment_no='experiment_3',\n","             dataset_name='pru')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/135 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  1%|          | 1/135 [00:18<41:56, 18.78s/it]\u001b[A\n","  1%|▏         | 2/135 [00:50<49:57, 22.53s/it]\u001b[A\n","  2%|▏         | 3/135 [01:16<52:23, 23.81s/it]\u001b[A\n","  3%|▎         | 4/135 [01:48<56:57, 26.09s/it]\u001b[A\n","  4%|▎         | 5/135 [02:15<57:00, 26.31s/it]\u001b[A\n","  4%|▍         | 6/135 [02:50<1:02:43, 29.18s/it]\u001b[A\n","  5%|▌         | 7/135 [03:02<50:40, 23.76s/it]  \u001b[A"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-c9c2fb0e2565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m t3 = ta.Scan(x, y, p, diabetes,grid_downsample=.5,random_method='quantum',             \n\u001b[1;32m      2\u001b[0m              \u001b[0mexperiment_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'experiment_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m              dataset_name='pru')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, params, model, dataset_name, experiment_no, x_val, y_val, val_split, shuffle, round_limit, grid_downsample, random_method, seed, search_method, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, reduce_loss, last_epoch_value, clear_tf_session, disable_progress_bar, print_params, debug)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# input parameters section ends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_null\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36mruntime\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m                      disable=self.disable_progress_bar)\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_log\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/scan/scan_round.py\u001b[0m in \u001b[0;36mscan_round\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0m_hr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"unsupported operand type(s) for +: 'int' and 'numpy.str_'\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/talos/model/ingest_model.py\u001b[0m in \u001b[0;36mingest_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                       self.round_params)\n\u001b[0m","\u001b[0;32m<ipython-input-24-cb545a44a88f>\u001b[0m in \u001b[0;36mdiabetes\u001b[0;34m(x_train, y_train, x_val, y_val, params)\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;31m#validation_split=.3,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     verbose=0)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# modify the output model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"LXBpHogXLG3_","colab_type":"code","outputId":"a94c80c9-43c0-4c68-c70f-d0a406569324","executionInfo":{"status":"ok","timestamp":1551814594786,"user_tz":-60,"elapsed":1006,"user":{"displayName":"Valero Laparra","photoUrl":"","userId":"00355299981903664579"}},"colab":{"base_uri":"https://localhost:8080/","height":1992}},"source":["r = ta.Reporting('pru_experiment_3.csv')\n","# returns the results dataframe\n","aa = r.data\n","\n","aa.sort_values('loss')\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>round_epochs</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>first_neuron</th>\n","      <th>hidden_layers</th>\n","      <th>activation</th>\n","      <th>dropout</th>\n","      <th>batch_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17</th>\n","      <td>100</td>\n","      <td>0.374142</td>\n","      <td>0.828125</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>100</td>\n","      <td>0.375799</td>\n","      <td>0.833333</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>100</td>\n","      <td>0.395605</td>\n","      <td>0.821615</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>100</td>\n","      <td>0.398041</td>\n","      <td>0.826823</td>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>100</td>\n","      <td>0.403552</td>\n","      <td>0.807292</td>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>100</td>\n","      <td>0.406737</td>\n","      <td>0.815104</td>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>100</td>\n","      <td>0.406747</td>\n","      <td>0.816406</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>100</td>\n","      <td>0.432556</td>\n","      <td>0.794271</td>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.1</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>100</td>\n","      <td>0.436009</td>\n","      <td>0.795573</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.2</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>100</td>\n","      <td>0.438748</td>\n","      <td>0.790365</td>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.2</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>100</td>\n","      <td>0.440691</td>\n","      <td>0.809896</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>100</td>\n","      <td>0.444246</td>\n","      <td>0.799479</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.2</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100</td>\n","      <td>0.447048</td>\n","      <td>0.794271</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.2</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>100</td>\n","      <td>0.448132</td>\n","      <td>0.794271</td>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.3</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>100</td>\n","      <td>0.449968</td>\n","      <td>0.803385</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.4</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>100</td>\n","      <td>0.451154</td>\n","      <td>0.798177</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>100</td>\n","      <td>0.452219</td>\n","      <td>0.795573</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>100</td>\n","      <td>0.452421</td>\n","      <td>0.789062</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.1</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>100</td>\n","      <td>0.454213</td>\n","      <td>0.803385</td>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>100</td>\n","      <td>0.455246</td>\n","      <td>0.785156</td>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>100</td>\n","      <td>0.456567</td>\n","      <td>0.783854</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>100</td>\n","      <td>0.456671</td>\n","      <td>0.789062</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100</td>\n","      <td>0.457286</td>\n","      <td>0.787760</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.3</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>100</td>\n","      <td>0.457873</td>\n","      <td>0.786458</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.4</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>100</td>\n","      <td>0.458706</td>\n","      <td>0.790365</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>100</td>\n","      <td>0.458835</td>\n","      <td>0.789063</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>100</td>\n","      <td>0.458852</td>\n","      <td>0.789062</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>100</td>\n","      <td>0.458977</td>\n","      <td>0.786458</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>100</td>\n","      <td>0.460056</td>\n","      <td>0.791667</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.2</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>100</td>\n","      <td>0.463497</td>\n","      <td>0.792969</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.4</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>100</td>\n","      <td>0.548835</td>\n","      <td>0.717448</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>100</td>\n","      <td>0.550165</td>\n","      <td>0.723958</td>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.4</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>100</td>\n","      <td>0.550670</td>\n","      <td>0.735677</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>100</td>\n","      <td>0.552507</td>\n","      <td>0.712240</td>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.3</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>100</td>\n","      <td>0.554042</td>\n","      <td>0.709635</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.4</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>100</td>\n","      <td>0.558072</td>\n","      <td>0.716146</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.4</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>100</td>\n","      <td>0.558275</td>\n","      <td>0.725260</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.2</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>100</td>\n","      <td>0.559665</td>\n","      <td>0.734375</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>100</td>\n","      <td>0.560409</td>\n","      <td>0.746094</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>100</td>\n","      <td>0.561306</td>\n","      <td>0.712240</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.4</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>100</td>\n","      <td>0.562500</td>\n","      <td>0.721354</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.3</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>100</td>\n","      <td>0.564478</td>\n","      <td>0.730469</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>100</td>\n","      <td>0.573762</td>\n","      <td>0.742187</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.2</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>100</td>\n","      <td>0.575313</td>\n","      <td>0.708333</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.4</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>100</td>\n","      <td>0.577929</td>\n","      <td>0.722656</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.3</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>100</td>\n","      <td>0.580802</td>\n","      <td>0.705729</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.4</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>100</td>\n","      <td>0.585760</td>\n","      <td>0.708333</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.3</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>100</td>\n","      <td>0.587710</td>\n","      <td>0.684896</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.2</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>100</td>\n","      <td>0.636766</td>\n","      <td>0.656250</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.4</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>100</td>\n","      <td>5.582965</td>\n","      <td>0.653646</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.1</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>100</td>\n","      <td>5.583357</td>\n","      <td>0.653646</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.2</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>100</td>\n","      <td>5.624544</td>\n","      <td>0.651042</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.3</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>100</td>\n","      <td>5.624544</td>\n","      <td>0.651042</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.1</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>100</td>\n","      <td>5.624544</td>\n","      <td>0.651042</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.3</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>100</td>\n","      <td>5.624544</td>\n","      <td>0.651042</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>100</td>\n","      <td>5.624544</td>\n","      <td>0.651042</td>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>100</td>\n","      <td>5.624544</td>\n","      <td>0.651042</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>&lt;function elu at 0x7f5087d17158&gt;</td>\n","      <td>0.1</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>100</td>\n","      <td>10.379157</td>\n","      <td>0.348958</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.4</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>100</td>\n","      <td>10.379157</td>\n","      <td>0.348958</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>100</td>\n","      <td>10.379157</td>\n","      <td>0.348958</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>&lt;function relu at 0x7f5087d17378&gt;</td>\n","      <td>0.1</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>135 rows × 8 columns</p>\n","</div>"],"text/plain":["     round_epochs       loss       acc  first_neuron  hidden_layers  \\\n","17            100   0.374142  0.828125            48              2   \n","117           100   0.375799  0.833333            48              2   \n","81            100   0.395605  0.821615            48              2   \n","75            100   0.398041  0.826823            48              1   \n","67            100   0.403552  0.807292            24              1   \n","55            100   0.406737  0.815104            48              1   \n","41            100   0.406747  0.816406            24              2   \n","115           100   0.432556  0.794271            24              1   \n","7             100   0.436009  0.795573            48              2   \n","104           100   0.438748  0.790365            48              1   \n","32            100   0.440691  0.809896            24              2   \n","74            100   0.444246  0.799479            48              0   \n","3             100   0.447048  0.794271            48              0   \n","64            100   0.448132  0.794271            48              1   \n","102           100   0.449968  0.803385            48              0   \n","129           100   0.451154  0.798177            48              2   \n","37            100   0.452219  0.795573            48              0   \n","94            100   0.452421  0.789062            24              0   \n","110           100   0.454213  0.803385            48              1   \n","100           100   0.455246  0.785156            24              1   \n","20            100   0.456567  0.783854            24              2   \n","83            100   0.456671  0.789062            48              0   \n","1             100   0.457286  0.787760            48              2   \n","106           100   0.457873  0.786458            12              0   \n","19            100   0.458706  0.790365            12              2   \n","116           100   0.458835  0.789063            12              2   \n","35            100   0.458852  0.789062            48              0   \n","101           100   0.458977  0.786458            48              0   \n","5             100   0.460056  0.791667            48              0   \n","72            100   0.463497  0.792969            24              0   \n","..            ...        ...       ...           ...            ...   \n","14            100   0.548835  0.717448            12              1   \n","9             100   0.550165  0.723958            24              1   \n","65            100   0.550670  0.735677            12              1   \n","98            100   0.552507  0.712240            24              1   \n","25            100   0.554042  0.709635            12              1   \n","29            100   0.558072  0.716146            24              2   \n","73            100   0.558275  0.725260            12              2   \n","132           100   0.559665  0.734375            12              1   \n","15            100   0.560409  0.746094            12              0   \n","130           100   0.561306  0.712240            12              1   \n","108           100   0.562500  0.721354            12              1   \n","48            100   0.564478  0.730469            12              0   \n","11            100   0.573762  0.742187            12              0   \n","90            100   0.575313  0.708333            12              1   \n","22            100   0.577929  0.722656            12              1   \n","49            100   0.580802  0.705729            12              2   \n","99            100   0.585760  0.708333            12              2   \n","46            100   0.587710  0.684896            12              2   \n","28            100   0.636766  0.656250            12              2   \n","33            100   5.582965  0.653646            12              0   \n","70            100   5.583357  0.653646            12              0   \n","134           100   5.624544  0.651042            48              0   \n","92            100   5.624544  0.651042            12              0   \n","31            100   5.624544  0.651042            12              0   \n","57            100   5.624544  0.651042            12              1   \n","131           100   5.624544  0.651042            24              1   \n","16            100   5.624544  0.651042            24              0   \n","68            100  10.379157  0.348958            24              0   \n","105           100  10.379157  0.348958            24              0   \n","34            100  10.379157  0.348958            12              0   \n","\n","                            activation  dropout  batch_size  \n","17    <function elu at 0x7f5087d17158>      0.0          10  \n","117   <function elu at 0x7f5087d17158>      0.0          10  \n","81    <function elu at 0x7f5087d17158>      0.0          20  \n","75    <function elu at 0x7f5087d17158>      0.0          20  \n","67    <function elu at 0x7f5087d17158>      0.0          10  \n","55    <function elu at 0x7f5087d17158>      0.0          30  \n","41    <function elu at 0x7f5087d17158>      0.0          10  \n","115   <function elu at 0x7f5087d17158>      0.1          10  \n","7     <function elu at 0x7f5087d17158>      0.2          20  \n","104   <function elu at 0x7f5087d17158>      0.2          30  \n","32   <function relu at 0x7f5087d17378>      0.0          20  \n","74    <function elu at 0x7f5087d17158>      0.2          30  \n","3     <function elu at 0x7f5087d17158>      0.2          20  \n","64    <function elu at 0x7f5087d17158>      0.3          30  \n","102   <function elu at 0x7f5087d17158>      0.4          20  \n","129  <function relu at 0x7f5087d17378>      0.1          30  \n","37    <function elu at 0x7f5087d17158>      0.0          30  \n","94    <function elu at 0x7f5087d17158>      0.1          10  \n","110  <function relu at 0x7f5087d17378>      0.1          30  \n","100   <function elu at 0x7f5087d17158>      0.0          30  \n","20   <function relu at 0x7f5087d17378>      0.0          30  \n","83    <function elu at 0x7f5087d17158>      0.1          30  \n","1     <function elu at 0x7f5087d17158>      0.3          20  \n","106   <function elu at 0x7f5087d17158>      0.4          10  \n","19    <function elu at 0x7f5087d17158>      0.0          20  \n","116   <function elu at 0x7f5087d17158>      0.0          20  \n","35    <function elu at 0x7f5087d17158>      0.0          10  \n","101   <function elu at 0x7f5087d17158>      0.0          20  \n","5     <function elu at 0x7f5087d17158>      0.2          10  \n","72    <function elu at 0x7f5087d17158>      0.4          10  \n","..                                 ...      ...         ...  \n","14    <function elu at 0x7f5087d17158>      0.1          30  \n","9     <function elu at 0x7f5087d17158>      0.4          10  \n","65   <function relu at 0x7f5087d17378>      0.1          30  \n","98   <function relu at 0x7f5087d17378>      0.3          30  \n","25    <function elu at 0x7f5087d17158>      0.4          30  \n","29   <function relu at 0x7f5087d17378>      0.4          10  \n","73   <function relu at 0x7f5087d17378>      0.2          20  \n","132  <function relu at 0x7f5087d17378>      0.1          30  \n","15   <function relu at 0x7f5087d17378>      0.0          20  \n","130   <function elu at 0x7f5087d17158>      0.4          20  \n","108  <function relu at 0x7f5087d17378>      0.3          10  \n","48   <function relu at 0x7f5087d17378>      0.1          30  \n","11   <function relu at 0x7f5087d17378>      0.2          20  \n","90    <function elu at 0x7f5087d17158>      0.4          30  \n","22   <function relu at 0x7f5087d17378>      0.3          20  \n","49   <function relu at 0x7f5087d17378>      0.4          10  \n","99   <function relu at 0x7f5087d17378>      0.3          10  \n","46   <function relu at 0x7f5087d17378>      0.2          30  \n","28   <function relu at 0x7f5087d17378>      0.4          20  \n","33    <function elu at 0x7f5087d17158>      0.1          20  \n","70   <function relu at 0x7f5087d17378>      0.2          20  \n","134  <function relu at 0x7f5087d17378>      0.3          30  \n","92    <function elu at 0x7f5087d17158>      0.1          30  \n","31   <function relu at 0x7f5087d17378>      0.3          30  \n","57    <function elu at 0x7f5087d17158>      0.0          30  \n","131   <function elu at 0x7f5087d17158>      0.0          20  \n","16    <function elu at 0x7f5087d17158>      0.1          20  \n","68   <function relu at 0x7f5087d17378>      0.4          10  \n","105  <function relu at 0x7f5087d17378>      0.0          10  \n","34   <function relu at 0x7f5087d17378>      0.1          20  \n","\n","[135 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":69}]}]}